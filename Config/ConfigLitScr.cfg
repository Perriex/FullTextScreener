[general]
appVersion = 0.7.0
# Whether to index documents in `inputDir` before launching the chatbot UI
forceReindex = False
# Whether to log INFO and WARNING messages
enableLogging = True
# Whether to show low level progress bars, if set to False, only high level progress bar will be rendered. Only shown in the terminal.
showProgress = True

[llm-model]
service = huggingface
# The LLM used by the chatbot components
# LLM generation parameters
# max number of tokens to generate in one round
max_new_tokens = 1024
# temperature for sampling from the LLM model (0.0 = greedy sampling, 1.0 = random sampling)
temperature = 0.0
 # whether to sample from the LLM model
do_sample = False

[huggingface]
api_key = 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
# model_name = mistralai/Mistral-7B-Instruct-v0.3
model_name = Qwen/Qwen2.5-14B-Instruct-1M
# model_name = meta-llama/Llama-3.1-8B-Instruct
# embed_model = BAAI/bge-small-en-v1.5
# embedDim = 384
embed_model = Alibaba-NLP/gte-multilingual-base
embedDim = 768


[mistral]
api_key = XnDLoDcVRA9fVtlIcCvVhaWrmxkpsxd9
model_name = mistral-large-latest
# embed_model = mistral-embed
# embedDim = 1024
embed_model = Alibaba-NLP/gte-multilingual-base
embedDim = 768

[neo4j]
username = neo4j
password = neo4j_rag_poc 
url1 = bolt://localhost:7687
url2 = http://localhost:7474
containerName = neo4j-apoc

[dir-structure]
inputDir = ./input/selected
input_pdf_folder = ./input/pdfs
metadataFile = ./input/metadata.csv
outputDir = ./output
outputFile = ./output/output.json
logDir = ./logs/
logFile = processing_log.txt
dataPath = ../neo4j_vol1/data
pluginsPath = ../neo4j_vol1/plugins

[agent]
# number of iterations to run the agent
max_iterations = 10


[retriever]
# Default retriever parameters
vectorTopK = 10
cutoffScore = 0.5

[nodeparser]
# Node parser approach, can be either `static` or `semantic`
nodeParserType = static
# Number of documents to process at a time, larger values may lead to hitting the embedding API rate limit
batchSize = 1
# Number of tokens to include in each chunk
chunk_size = 1000
# The overlap between subsequent chunks
chunk_overlap = 50

# The following are applicable only to the Semantic Splitter
# Default = 1, Adjust buffer size as needed
bufferSize = 1
# Default = 95, lower values result in too many small chunks
breakpointPercentileThreshold = 95
